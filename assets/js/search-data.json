{
  
    
        "post0": {
            "title": "How to get plotly working with FastPages",
            "content": "# Basic plotly figure import plotly.express as px import plotly.io as pio from IPython.display import HTML pio.templates.default = &quot;seaborn&quot; gapminder = px.data.gapminder() fig = px.violin( gapminder, x=&quot;continent&quot;, y=&quot;lifeExp&quot;, color=&quot;continent&quot;, labels={&quot;lifeExp&quot;: &quot;life expectancy at birth&quot;}, ) . Now that we have the figure, if we were to simply run fig.show() we would be able to see the figure locally but the jekyll build will fail when trying to render the page. In order to get the figure to show locally and on the blog post we have to use a workaround. . First you will need to add a hide tag at the beginning of the code block. . This will tell jekyll (i think?) to ignore the output and not show any of it, because it is now being ignored the errors are gone. But, we now dont have a plot on the blog post, to get it to render will need to follow the next step. . To get the figure to render on the blog you will need to convert the figure to html, and specify the js (specifing the js is crucial, it will not work otherwise). Then use IPython to render the HTML. You can add a hide_input tag to hide this block but show the plot . . .",
            "url": "https://jprier.github.io/josh-blog/plotly/tutorial/2021/02/12/plotlyWithFastPages.html",
            "relUrl": "/plotly/tutorial/2021/02/12/plotlyWithFastPages.html",
            "date": " • Feb 12, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Understanding The Data -- Minecraft Mining",
            "content": "What is the Optimal Method to Mine in Minecraft . To answer this question we must first collect data. To do this I created a minecraft mod that randomly teleports the player, samples a 500x50x500 (X,Y,Z) set of blocks around the player and logs those blocks into a csv. It repeats this a total of 10 times creating 10 samples of 500x50x500 blocks . The mod can be seen here: https://github.com/JPrier/MinecraftBlocksDistribution . With this we get 128 million blocks from a single seed, doing this on multiple seeds will explode the data size . Data . Here we will use Pandas to read in the data to be used to visualize distributions. . import pandas as pd import plotly.express as px from IPython.display import HTML . . Visualize Distributions . Here we want to visualize the blocks and their frequency . # Adjust samples to be same distance from player df[&quot;XFromPlayer&quot;] = df[&quot;playerX&quot;] - df[&quot;X&quot;] df[&quot;ZFromPlayer&quot;] = df[&quot;playerZ&quot;] - df[&quot;Z&quot;] # Get blocks that we care about importantBlocks = [&#39;coal_ore&#39;, &#39;gold_ore&#39;, &#39;iron_ore&#39;, &#39;diamond_ore&#39;, &#39;lapis_ore&#39;, &#39;redstone_ore&#39;, &#39;emerald_ore&#39;] specialBlocks = [&#39;diamond_ore&#39;, &#39;lapis_ore&#39;, &#39;redstone_ore&#39;, &#39;emerald_ore&#39;] df_blocks = df.loc[df[&#39;Block&#39;].isin(importantBlocks)] df_special_blocks = df.loc[df[&#39;Block&#39;].isin(specialBlocks)] # Get blocks for only 1 sample df_blocks_sample_0 = df_blocks.loc[df_blocks[&#39;sample&#39;] == 0] df_special_sample_0 = df_special_blocks.loc[df_special_blocks[&#39;sample&#39;] == 0] . # Create distribution plots of block vs Y level fig = px.histogram(df_blocks, x=&quot;Y&quot;, color=&quot;Block&quot;) # HTML(fig.to_html(include_plotlyjs=&#39;cdn&#39;)) . . . # HeatMaps of blocks fig1 = px.density_heatmap(df_special_blocks, x=&quot;XFromPlayer&quot;, y=&quot;Y&quot;, title=&quot;YvsX all samples&quot;) fig2 = px.density_heatmap(df_special_blocks, x=&quot;ZFromPlayer&quot;, y=&quot;Y&quot;, title=&quot;YvsZ all samples&quot;) fig3 = px.density_heatmap(df_special_blocks, x=&quot;XFromPlayer&quot;, y=&quot;ZFromPlayer&quot;, title=&quot;XvsZ all samples&quot;) fig4 = px.density_heatmap(df_special_sample_0, x=&quot;XFromPlayer&quot;, y=&quot;Y&quot;, title=&quot;YvsX sample 0&quot;) fig5 = px.density_heatmap(df_special_sample_0, x=&quot;ZFromPlayer&quot;, y=&quot;Y&quot;, title=&quot;YvsZ sample 0&quot;) fig6 = px.density_heatmap(df_special_sample_0, x=&quot;XFromPlayer&quot;, y=&quot;ZFromPlayer&quot;, title=&quot;XvsZ sample 0&quot;) . . . . . . . . . . . . . From these heatmaps we can see that generally all the special blocks are located around the same Y level . # 3D Scatter plot of special blocks fig = px.scatter_3d(df_special_sample_0, x=&#39;XFromPlayer&#39;, y=&#39;ZFromPlayer&#39;, z=&#39;Y&#39;, color=&#39;Block&#39;) fig1 = px.scatter_3d(df_special_blocks, x=&#39;X&#39;, y=&#39;Z&#39;, z=&#39;Y&#39;, color=&#39;Block&#39;) . . . . . What can we see from the Data . Looking at the graphs we can get an idea for the distribution of different blocks. . With the heatmaps we can see that the blocks we normally want to mine for stick generally to a specific set of Y values . What is the best method . Now that we have the data and have seen the distributions of blocks through our samples lets see how different methods of mining do. . Naive way . The naive and simple way to pick the best mining strat is to find the Y levels where the block you want is highest and mine there. Additionally looking at the distributions we can see that most of the blocks are distributed fairly even so strip mining would be the simpilest way to mine. But we will continue to see if those naive assumptions will hold up. . Calculating the best method . We will compare each of the methods based on these data points: . Number of blocks mined | Number of desired blocks mined | Reward value for blocks mined Ex: reward = 10*numberOfDiamonds + 0.1*numberOfIron - 20*LavaPoolsRunInto | . | . TODO (What to figure out) . Should methods be done on every level and each be compared? | If a player sees diamonds they will mine all of them, need to grab all visible ore | . # Starting from the player calculate each of the methods at different starting levels. save each into a dataframe def strip_mining(): # +250X @ Y, Y+1, -250X @ Y, Y+1 -- repeat for +2Z, -2Z # # Get range of coords. Should be an O(1) process by just selecting a set of blocks from coords given the player&#39;s starting location # # Create tuples [X, Y, Z] and get the blocks at those coords. Need to also grab all &quot;visible&quot; blocks (need a method to &quot;mine&quot;) # # # Strip 1 xRange = [0, 250], yRange = [0, 1], zRange = [0] # repeat each 3 Z s.t. there are 2 blocks in between strips # Need zRange = [0, 3, 6, 9, ..., Z&lt;=250] pass # Calculate the frequency of blocks seen with each method at different levels # Show the &quot;Scores&quot; .",
            "url": "https://jprier.github.io/josh-blog/minecraft/understanding%20the%20data/data%20science/2021/02/12/MinecraftBlocks.html",
            "relUrl": "/minecraft/understanding%20the%20data/data%20science/2021/02/12/MinecraftBlocks.html",
            "date": " • Feb 12, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Understanding The Data -- Kovaaks Aim Trainer",
            "content": "Kovaaks . Kovaaks is a &quot;game&quot; that allows to directly practice mouse control in 3d fps games. There are hundreds of different mini-games to practice with, each having a different focus. . This guide is best for getting perspective or understanding how and why to use Kovaaks . File Names . Kovaaks has a great feature in which it saves every mini-game&#39;s stats to a csv. The format of the csv&#39;s names is as follows . &lt;scenario name&gt; - &lt;Challenge or Freeplay&gt; - YYYY.MM.DD-HH.MM.SS Stats.csv . Example: . Tile Frenzy - Challenge - 2020.12.14-08.46.00 Stats.csv . Some of the scenario names also have dashes so just checking against the first dash will not work . Tile Frenzy - Strafing - 03 - Challenge - 2020.12.14-08.34.31 Stats.csv . The Data . Each file has 4 parts: . List of all Kills | Weapon, shots, hits, damage done, damage possible | Overall Stats and info | Info about settings (input lag, fps, sens, FOV, etc) | . import pandas as pd import matplotlib.pyplot as plt from urllib.request import urlopen from io import StringIO import plotly.express as px from IPython.display import HTML . . Each part of the data has different formats and headers. Here are the Headers/keys in python . keys_kills=[&quot;Date&quot;,&quot;Kill #&quot;,&quot;Timestamp&quot;,&quot;Bot&quot;,&quot;Weapon&quot;,&quot;TTK&quot;,&quot;Shots&quot;,&quot;Hits&quot;,&quot;Accuracy&quot;,&quot;Damage Done&quot;,&quot;Damage Possible&quot;,&quot;Efficiency&quot;,&quot;Cheated&quot;] keys_weapon=[&quot;Date&quot;,&quot;Weapon&quot;,&quot;Shots&quot;,&quot;Hits&quot;,&quot;Damage Done&quot;,&quot;Damage Possible&quot;] keys_info=[&quot;Date&quot;,&quot;Kills&quot;,&quot;Deaths&quot;,&quot;Fight Time&quot;,&quot;Avg TTK&quot;,&quot;Damage Done&quot;,&quot;Damage Taken&quot;,&quot;Midairs&quot;,&quot;Midaired&quot;,&quot;Directs&quot;,&quot;Directed&quot;,&quot;Distance Traveled&quot;,&quot;Score&quot;,&quot;Scenario&quot;,&quot;Hash&quot;,&quot;Game Version&quot;,&quot;Challenge Start&quot;,&quot;Input Lag&quot;,&quot;Max FPS (config)&quot;,&quot;Sens Scale&quot;,&quot;Horiz Sens&quot;,&quot;Vert Sens&quot;,&quot;FOV&quot;,&quot;Hide Gun&quot;,&quot;Crosshair&quot;,&quot;Crosshair Scale&quot;,&quot;Crosshair Color&quot;,&quot;Resolution&quot;,&quot;Avg FPS&quot;,&quot;Resolution Scale&quot;] keys_info_no_colon=[&quot;Resolution&quot;,&quot;Avg FPS&quot;,&quot;Resolution Scale&quot;] . . #HELPERS def split_format_file(section, output, date): split_section = section.split(&#39; n&#39;) # if output == &quot;&quot;: # output = split_section[0] # TODO: Add date to each line for i in range(len(split_section[1:])): if split_section[i+1][-1] == &#39;,&#39;: split_section[i+1] = split_section[i+1][:-1] split_section[i+1] = date + &quot;,&quot; + split_section[i+1] section = &#39; n&#39;.join(split_section[1:]) output = output + &#39; n&#39; + section return output def format_info(info, output, date): info_lines = info.split(&#39; n&#39;) data = [] for key in keys_info: if key == &quot;Date&quot;: found_key = True data.append(date) else: found_key = False for line in info_lines: if any(key in line for key in keys_info_no_colon): split_line = line.split(&#39;,&#39;) if len(split_line) &gt; 1: if split_line[0] == key: found_key = True data.append(split_line[1]) else: split_line = line.split(&#39;:&#39;, 1) if len(split_line) &gt; 1: if split_line[0] == key: found_key = True data.append(split_line[1][1:]) if not found_key: data.append(&#39;&#39;) output = output + &#39; n&#39; + &#39;,&#39;.join(data) return output . . # Current online directory for my stats stat_dir = &quot;https://jprier.github.io/stats/&quot; stat_filenames_url = &quot;https://jprier.github.io/stats/filenames.txt&quot; stat_filenames = urlopen(stat_filenames_url).read().decode(&#39;utf-8&#39;).split(&#39; n&#39;) kills = &#39;,&#39;.join(keys_kills) weapon = &#39;,&#39;.join(keys_weapon) info = &#39;,&#39;.join(keys_info) for filename in stat_filenames: # TODO: parse filename for challenge name and date try: filename = filename.replace(&#39; &#39;, &#39;%20&#39;) file = urlopen(stat_dir + filename).read().decode(&#39;utf-8&#39;).split(&#39; n n&#39;) if len(file) &gt; 1: date = filename.split(&#39;%20&#39;)[-2] # TODO: Add challenge name and date to each as columns kills = split_format_file(file[0], kills, date) # file[1] --&gt; df_weapon weapon = split_format_file(file[1], weapon, date) # file[2,3] --&gt; df_info info = format_info(file[2]+&quot; n&quot;+file[3], info, date) except Exception as err: print(err) df_kills = pd.read_csv(StringIO(kills), sep=&quot;,&quot;) df_weapons = pd.read_csv(StringIO(weapon), sep=&quot;,&quot;) df_info = pd.read_csv(StringIO(info), sep=&quot;,&quot;) df_kills[&quot;Date&quot;] = pd.to_datetime(df_kills.Date, format=&#39;%Y.%m.%d-%H.%M.%S&#39;)#df_kills[&quot;Date&quot;].dt.strftime(&quot;%Y.%d.%m-%H.%M.%S&quot;) df_weapons[&quot;Date&quot;] = pd.to_datetime(df_weapons.Date, format=&#39;%Y.%m.%d-%H.%M.%S&#39;)#df_weapons[&quot;Date&quot;].dt.strftime(&quot;%Y.%d.%m-%H.%M.%S&quot;) df_info[&quot;Date&quot;] = pd.to_datetime(df_info.Date, format=&#39;%Y.%m.%d-%H.%M.%S&#39;)#df_info[&quot;Date&quot;].dt.strftime(&quot;%Y.%d.%m-%H.%M.%S&quot;) . Visualizing the Data . scenarios = df_info[&#39;Scenario&#39;].unique() scenario, scenarios = scenarios[0], scenarios[1:] df_info_max = df_info.loc[df_info[&#39;Scenario&#39;] == scenario].resample(&#39;D&#39;)[&#39;Score&#39;].agg([&#39;max&#39;]) df_info_max[&#39;Scenario&#39;] = scenario for scenario in scenarios: df_info_max_scenario = df_info.loc[df_info[&#39;Scenario&#39;] == scenario].resample(&#39;D&#39;)[&#39;Score&#39;].agg([&#39;max&#39;]) df_info_max_scenario = df_info_max_scenario[df_info_max_scenario[&#39;max&#39;].notna()] if df_info_max_scenario.size &gt; 3: df_info_max_scenario[&#39;Scenario&#39;] = scenario df_info_max = df_info_max.append(df_info_max_scenario) with pd.option_context(&#39;display.max_rows&#39;, 10, &#39;display.max_columns&#39;, None): display(df_info_max) fig = px.line(df_info_max, x=df_info_max.index, y=&quot;max&quot;, color=&#39;Scenario&#39;) fig1 = px.scatter(df_info, x=df_info.index, y=&quot;Score&quot;, trendline=&#39;lowess&#39;, color=&#39;Scenario&#39;) . . . . .",
            "url": "https://jprier.github.io/josh-blog/kovaaks/understanding%20the%20data/data%20science/2021/02/12/KovaaksData.html",
            "relUrl": "/kovaaks/understanding%20the%20data/data%20science/2021/02/12/KovaaksData.html",
            "date": " • Feb 12, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Notes From NNFS",
            "content": "Wanting to relearn the ML basics from my university degree I started going through the course Neural Networks From Scratch. . This post contains my notes and learnings from the course. . The Basics of a Layer . A layer of a neural network contains 1 or more neurons, these neurons will take a vector (or matrix with batches) as input and have a vector of weights to multiply by each of the inputs and a bias to add to the input*weights. . input = [1, 2] weights = [1,2] bias = 1 # output of a single neuron output = inputs*weights + bias . This is easily scaled up to multiple neurons with matrices . import numpy as np inputs = [1.0, 2.0, 3.0, 2.5] weights = [[0.2, 0.8, -0.5, 1], [0.5, -0.91, 0.26, -0.5], [-0.26, -0.27, 0.17, 0.87]] biases = [2.0, 3.0, 0.5] layer_outputs = np.dot(weights, inputs) + biases . Tip: numpy shape has an out to in order s.t. in shape(x,y) x is the size of the outmost dimension and y is the size of the most inner dimension . Each layer is essentially the dot product the weights and the previous layer’s output (input data for the first layer) . Batches . In the previous examples we take a vector as an input input = [1,2]. This vector is a single object in our dataset, this can be an image of a dog, the values a house sold, (x,y) values of a point, or anything else. Each value is a feature of the object, a feature describes some aspect of the object. In the case of points on a 2d graph the features for the objects would be the x and y coordinates of each point so our input in this case would be [x, y]. . We do not want to pass a single object as input for each pass of the neural network, this would be slow and would take forever for large datasets. Instead of passing single objects we can pass multiple objects at once in what is called a batch. . A batch will contain 2 or more vectors, typically we have batch sizes of 16-64 with 32 being common. Too small of a batch size will cause the neural network to underfit, this is due to the model not getting enough information in each pass causing it to make too large of a change to the parameters on each pass. Too large of a batch size will cause the neural network to overfit, this is due to it fitting to too much of the sample data at once which will cause the test accuracy to be much lower. . Activation Functions . The Basics . The activation function is a tool to adjust how and when a neuron of the network should activate. A network will typically use a different activation function between the output and hidden layers. . We use the activation function with the calculation of the weights, inputs, and bias per neuron . output = Activaiton(weights*input + bias) . Step Function . A simple activation function is the step function . x = weights*inputs + bias if x &gt; 0 y = 1 else y = 0 . The step function is a binary on or off for a neuron, 1 or 0 depending on the value of the calculation . Linear Activation Function . Sigmoid Function . ReLU .",
            "url": "https://jprier.github.io/josh-blog/studying/2020/12/12/NNFS-Notes.html",
            "relUrl": "/studying/2020/12/12/NNFS-Notes.html",
            "date": " • Dec 12, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "A Software Development Engineer that wants to learn as much as possible .",
          "url": "https://jprier.github.io/josh-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://jprier.github.io/josh-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}